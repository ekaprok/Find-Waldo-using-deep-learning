{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "DATA PREPROCESSING/EXPLORATION STEP\n",
    "'''\n",
    "\n",
    "'''\n",
    "Implement data augmentation on Waldo images using Keras\n",
    "'''\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from sklearn.datasets import load_files\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm # Used for the progress bar visualization\n",
    "import random\n",
    "\n",
    "# Declare the data generation object for data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255, # rescale the image before feeding it to the cnn\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGenerate augmented images for waldo (do it only once)\\n'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Generate augmented images for waldo (do it only once)\n",
    "'''\n",
    "# waldo_filenames = np.array(glob(\"waldo_dataset/original_waldo/*\"))\n",
    "# for filename in waldo_filenames:\n",
    "#     img = load_img(filename)\n",
    "#     x = img_to_array(img)\n",
    "#     x = x.reshape((1,) + x.shape)\n",
    "#     i = 0\n",
    "#     for batch in datagen.flow(x, batch_size=1,\n",
    "#                               save_to_dir='waldo_dataset/train/waldo', \n",
    "#                               save_prefix='new_waldo', \n",
    "#                               save_format='jpg'):\n",
    "#         i += 1\n",
    "#         if i > 20:\n",
    "#             break  # the flow may yield batches indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waldo dataset contains 609 images\n",
      "Notwaldo dataset contains 5337 images\n"
     ]
    }
   ],
   "source": [
    "# The following function loads a data set along with the targets \n",
    "# Note that the directory has to have at least two folders containing different classes\n",
    "# The following function was taken from dog breed classification project\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    files = np.array(data['filenames'])\n",
    "    targets = np.array(data['target'])\n",
    "    return files, targets\n",
    "\n",
    "# Declare the training (all_files) and test datasets along with their labels\n",
    "all_files, all_targets = load_dataset('waldo_dataset/train_32')\n",
    "test_files, test_targets = load_dataset('waldo_dataset/test')\n",
    "\n",
    "\n",
    "# Shuffle the data to avoid a bias\n",
    "rand = np.random.RandomState(10)\n",
    "shuffle = rand.permutation(len(all_files))\n",
    "all_files, all_targets = all_files[shuffle], all_targets[shuffle]\n",
    "\n",
    "\n",
    "# Show statistics about the data\n",
    "waldoFiles = np.array(glob(\"waldo_dataset/train_32/waldo/*\"))\n",
    "notWaldoFiles = np.array(glob(\"waldo_dataset/train_32/notwaldo/*\"))\n",
    "print('Waldo dataset contains ' + str(len(waldoFiles)) + ' images')\n",
    "print('Notwaldo dataset contains ' + str(len(notWaldoFiles)) + ' images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use this function to resize an image into 32x32 size\n",
    "def resize_img(filename, key):\n",
    "    image = cv2.imread(filename)\n",
    "    r = 100.0 / image.shape[1]\n",
    "    dim = (100, int(image.shape[0] *r))\n",
    "    imageresized = cv2.resize(image,(32,32),dim,interpolation = cv2.INTER_AREA)\n",
    "    cv2.imwrite('imageresized_{}.jpg'.format(key), imageresized)\n",
    "    \n",
    "# Use this code to resize all the images in the directory (use it only once)\n",
    "# waldoFilesnew = np.array(glob(\"waldo_dataset/test/waldo/*\"))\n",
    "# key = 0    \n",
    "# for image_file in waldoFilesnew:\n",
    "#     resize_img(image_file, key)\n",
    "#     key += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ekaterina/anaconda/lib/python3.6/site-packages/skimage/feature/_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "CREATE THE SVM CLASSIFIER\n",
    "'''\n",
    "from skimage.feature import hog\n",
    "import skimage as skimage\n",
    "\n",
    "# Calculate HOGs for all the images in the training set\n",
    "hog_descriptors = []\n",
    "for img in all_files:\n",
    "    timg = skimage.color.rgb2grey(cv2.imread(img))\n",
    "    hog_descriptors.append(skimage.feature.hog(timg, orientations=9, pixels_per_cell=(8, 8), \n",
    "                                      cells_per_block=(3, 3), \n",
    "                                      visualise=False, \n",
    "                                      transform_sqrt=False, \n",
    "                                      feature_vector=True, \n",
    "                                      normalise=None))\n",
    "\n",
    "# Calculate HOGs for all the images in the testing set\n",
    "hog_descriptors_test = []\n",
    "for img in test_files:\n",
    "    timg = skimage.color.rgb2grey(cv2.imread(img))\n",
    "    hog_descriptors_test.append(skimage.feature.hog(timg, orientations=9, pixels_per_cell=(8, 8), \n",
    "                                      cells_per_block=(3, 3), \n",
    "                                      visualise=False, \n",
    "                                      transform_sqrt=False, \n",
    "                                      feature_vector=True, \n",
    "                                      normalise=None))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model was trained in 15.020182132720947 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train SVM model\n",
    "from sklearn.svm import SVC\n",
    "from time import time\n",
    "\n",
    "t0=time()\n",
    "clf = SVC(probability=True, random_state=169)\n",
    "clf.fit(hog_descriptors, all_targets)\n",
    "t1=time()\n",
    "print('The model was trained in ' + str(t1 - t0) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy score of the SVM classifier is  0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ekaterina/anaconda/lib/python3.6/site-packages/skimage/feature/_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TEST THE SVM CLASSIFIER\n",
    "'''\n",
    "count_correct = 0\n",
    "threshold = 0.5\n",
    "for i in range(len(hog_descriptors_test)):\n",
    "    # waldo probability\n",
    "    waldo_prob = np.squeeze(clf.predict_proba(hog_descriptors_test[i].reshape(1, -1)))[1]\n",
    "    if ((waldo_prob < threshold and test_targets[i] == 0) or (waldo_prob >= threshold and test_targets[i] == 1)):\n",
    "        count_correct += 1\n",
    "print('the accuracy score of the SVM classifier is ', count_correct / len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5946 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|▌         | 345/5946 [00:00<00:01, 3402.96it/s]\u001b[A\n",
      " 12%|█▏        | 702/5946 [00:00<00:01, 3490.02it/s]\u001b[A\n",
      " 18%|█▊        | 1074/5946 [00:00<00:01, 3562.64it/s]\u001b[A\n",
      " 24%|██▍       | 1446/5946 [00:00<00:01, 3600.39it/s]\u001b[A\n",
      " 31%|███       | 1817/5946 [00:00<00:01, 3621.64it/s]\u001b[A\n",
      " 36%|███▋      | 2158/5946 [00:00<00:01, 3585.63it/s]\u001b[A\n",
      " 42%|████▏     | 2512/5946 [00:00<00:00, 3578.97it/s]\u001b[A\n",
      " 49%|████▊     | 2887/5946 [00:00<00:00, 3599.46it/s]\u001b[A\n",
      " 55%|█████▍    | 3250/5946 [00:00<00:00, 3603.10it/s]\u001b[A\n",
      " 61%|██████    | 3603/5946 [00:01<00:00, 3594.29it/s]\u001b[A\n",
      " 67%|██████▋   | 3973/5946 [00:01<00:00, 3604.88it/s]\u001b[A\n",
      " 73%|███████▎  | 4331/5946 [00:01<00:00, 3601.83it/s]\u001b[A\n",
      " 79%|███████▉  | 4694/5946 [00:01<00:00, 3603.53it/s]\u001b[A\n",
      " 85%|████████▍ | 5054/5946 [00:01<00:00, 3602.87it/s]\u001b[A\n",
      " 91%|█████████▏| 5438/5946 [00:01<00:00, 3618.25it/s]\u001b[A\n",
      " 98%|█████████▊| 5822/5946 [00:01<00:00, 3631.73it/s]\u001b[A\n",
      "100%|██████████| 5946/5946 [00:01<00:00, 3627.25it/s]\u001b[A\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 3050.07it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "'''\n",
    "CREATE THE CNN CLASSIFIER\n",
    "'''\n",
    "\n",
    "# Preprocess the images in order to use Keras with tensorflow backend\n",
    "# (I took this code from the dog breed classification project)\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(32, 32))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (64, 64, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 64, 64, 3) and return 4D tensor\n",
    "    result = np.expand_dims(x, axis=0)\n",
    "    return result\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "train_tensors = paths_to_tensor(all_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 32, 32, 16)        784       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 16, 16, 32)        8224      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 8, 8, 64)          32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 42,865\n",
      "Trainable params: 42,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Declare the convolutional neural network\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=4, strides=1, padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=4, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4756 samples, validate on 1190 samples\n",
      "Epoch 1/4\n",
      "4700/4756 [============================>.] - ETA: 0s - loss: 0.2855 - acc: 0.8970Epoch 00000: val_loss improved from inf to 0.16843, saving model to saved_models/best.hdf5\n",
      "4756/4756 [==============================] - 5s - loss: 0.2833 - acc: 0.8978 - val_loss: 0.1684 - val_acc: 0.9261\n",
      "Epoch 2/4\n",
      "4720/4756 [============================>.] - ETA: 0s - loss: 0.1583 - acc: 0.9362Epoch 00001: val_loss improved from 0.16843 to 0.11885, saving model to saved_models/best.hdf5\n",
      "4756/4756 [==============================] - 5s - loss: 0.1585 - acc: 0.9363 - val_loss: 0.1188 - val_acc: 0.9613\n",
      "Epoch 3/4\n",
      "4720/4756 [============================>.] - ETA: 0s - loss: 0.1096 - acc: 0.9572Epoch 00002: val_loss improved from 0.11885 to 0.09405, saving model to saved_models/best.hdf5\n",
      "4756/4756 [==============================] - 5s - loss: 0.1112 - acc: 0.9565 - val_loss: 0.0940 - val_acc: 0.9588\n",
      "Epoch 4/4\n",
      "4700/4756 [============================>.] - ETA: 0s - loss: 0.0785 - acc: 0.9706Epoch 00003: val_loss did not improve\n",
      "4756/4756 [==============================] - 5s - loss: 0.0789 - acc: 0.9699 - val_loss: 0.1355 - val_acc: 0.9479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12e09cba8>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "# Use this to save the model with the best score for future retraining\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_tensors, all_targets, \n",
    "          validation_split=0.2,\n",
    "          epochs=4, \n",
    "          batch_size=20, \n",
    "          callbacks=[checkpointer], \n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test the CNN Classifier\n",
    "'''\n",
    "def img_to_tensor(img):\n",
    "    result = np.expand_dims(img, axis=0)\n",
    "    return result\n",
    "\n",
    "def predict_waldo(img):\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    return np.squeeze(model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_correct = 0\n",
    "threshold = 0.6\n",
    "for i in range(len(test_files)):\n",
    "    file_path = test_files[i]\n",
    "    file = load_img(file_path, target_size=(32, 32))\n",
    "    file = image.img_to_array(file).astype('float32')/255\n",
    "    score = predict_waldo(file)\n",
    "    if ((score < threshold and test_targets[i] == 0) or (score >= threshold and test_targets[i] == 1)):\n",
    "        count_correct += 1\n",
    "        \n",
    "print('the accuracy score of the CNN classifier is ', count_correct / len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "OBJECT DETECTION PART\n",
    "'''\n",
    "# Note: since CNN showed better results than SVM with HOG I'm going to use CNN for the object detection part\n",
    "\n",
    "# Create a sliding window\n",
    "def sliding_window(image, stepSize, windowSize):\n",
    "    # slide a window across the image\n",
    "    for y in range(0, image.shape[0], stepSize):\n",
    "        for x in range(0, image.shape[1], stepSize):\n",
    "            # yield the current window\n",
    "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])\n",
    "\n",
    "# Create the image pyramid for more accurate results\n",
    "def pyramid(image, scale, minSize=(30, 30)):\n",
    "    # yield the original image\n",
    "    yield(image)\n",
    " \n",
    "    # keep looping over the pyramid\n",
    "    while True:\n",
    "        # compute the new dimensions of the image and resize it\n",
    "        w = int(image.shape[1] / scale)\n",
    "        image = resize_im(image, width=w)\n",
    " \n",
    "        # if the resized image does not meet the supplied minimum\n",
    "        # size, then stop constructing the pyramid\n",
    "        if image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n",
    "            break\n",
    " \n",
    "        # yield the next image in the pyramid\n",
    "        yield(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Save image from a window for hard negative mining'''\n",
    "img = image.load_img('test.jpg', target_size=(32, 32))\n",
    "img = image.img_to_array(img).astype('float32')/255\n",
    "def save_img(img, key):    \n",
    "#     cv2.imwrite('waldo_dataset/hard_neg/hardmin_{}.jpg'.format(key), cv2.cvtColor(img.astype('float32')*255, cv2.COLOR_RGB2BGR))\n",
    "    cv2.imwrite('waldo_dataset/hard_neg9/notwaldo/hardmin9_{}.jpg'.format(key), img.astype('float32')*255)\n",
    "\n",
    "# save_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TEST THE OBJECT DETECTION PART\n",
    "'''\n",
    "originalFiles = np.array(glob(\"waldo_dataset/original_images/*\"))\n",
    "threshold = 0.5\n",
    "\n",
    "from time import sleep\n",
    "image = cv2.imread(originalFiles[9])\n",
    "winW = 32\n",
    "winH = 32\n",
    "y_pred = []\n",
    "key = 0\n",
    "\n",
    "''' CHOOSE THE MODEL HERE '''\n",
    "model = load_model('saved_models/best.hdf5')\n",
    "# Probability at which images are going to be saved for hard negative mining\n",
    "percentage_chance = 0.6\n",
    "for resized in pyramid(image, scale=0.5):\n",
    "    for (x, y, window) in sliding_window(resized, stepSize=16, windowSize=(winW, winH)):\n",
    "            # if the window does not meet our desired window size, ignore it\n",
    "            window = window.astype('float32')/255\n",
    "            if window.shape[0] != winH or window.shape[1] != winW:\n",
    "                continue\n",
    "            if predict_waldo(window) > threshold:\n",
    "                if random.random() < percentage_chance:\n",
    "                    save_img(window, key)\n",
    "                cv2.rectangle(image, (x, y), (x + winW, y + winH), (255, 0, 0), 2)\n",
    "                key += 1\n",
    "                \n",
    "            # since we do not have a classifier, we'll just draw the window\n",
    "            clone = resized.copy()\n",
    "            cv2.rectangle(clone, (x, y), (x + winW, y + winH), (0, 255, 0), 2)\n",
    "            cv2.imshow(\"Window\", clone)\n",
    "            cv2.waitKey(33)\n",
    "            sleep(0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/424 [00:00<?, ?it/s]\u001b[A\n",
      " 84%|████████▍ | 358/424 [00:00<00:00, 3552.11it/s]\u001b[A\n",
      "100%|██████████| 424/424 [00:00<00:00, 3507.78it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 339 samples, validate on 85 samples\n",
      "Epoch 1/4\n",
      "320/339 [===========================>..] - ETA: 0s - loss: 0.0577 - acc: 0.9844Epoch 00000: val_loss improved from inf to 0.00048, saving model to saved_models/hard_neg9.hdf5\n",
      "339/339 [==============================] - 0s - loss: 0.0545 - acc: 0.9853 - val_loss: 4.7627e-04 - val_acc: 1.0000\n",
      "Epoch 2/4\n",
      "300/339 [=========================>....] - ETA: 0s - loss: 4.8409e-04 - acc: 1.0000Epoch 00001: val_loss improved from 0.00048 to 0.00009, saving model to saved_models/hard_neg9.hdf5\n",
      "339/339 [==============================] - 0s - loss: 4.3105e-04 - acc: 1.0000 - val_loss: 9.3516e-05 - val_acc: 1.0000\n",
      "Epoch 3/4\n",
      "300/339 [=========================>....] - ETA: 0s - loss: 1.3927e-04 - acc: 1.0000Epoch 00002: val_loss improved from 0.00009 to 0.00002, saving model to saved_models/hard_neg9.hdf5\n",
      "339/339 [==============================] - 0s - loss: 1.2388e-04 - acc: 1.0000 - val_loss: 2.3480e-05 - val_acc: 1.0000\n",
      "Epoch 4/4\n",
      "300/339 [=========================>....] - ETA: 0s - loss: 1.6906e-05 - acc: 1.0000Epoch 00003: val_loss improved from 0.00002 to 0.00001, saving model to saved_models/hard_neg9.hdf5\n",
      "339/339 [==============================] - 0s - loss: 1.5261e-05 - acc: 1.0000 - val_loss: 1.3402e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12da8b128>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Implement Hard Negative Mining\n",
    "'''\n",
    "# Upload the images generated during hard negative miining\n",
    "hard_neg9_files, hard_neg9_targets = load_dataset('waldo_dataset/hard_neg9')\n",
    "hard_neg9_train_tensors = paths_to_tensor(hard_neg9_files).astype('float32')/255\n",
    "\n",
    "# Load the pretrained model\n",
    "model = load_model('saved_models/best.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/hard_neg9.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "# Retrain the model\n",
    "model.fit(hard_neg9_train_tensors, hard_neg9_targets, \n",
    "          validation_split=0.2,\n",
    "          epochs=4, \n",
    "          batch_size=20, \n",
    "          callbacks=[checkpointer], \n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
