{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "DATA PREPROCESSING/EXPLORATION STEP\n",
    "'''\n",
    "\n",
    "'''\n",
    "Implement data augmentation on Waldo images using Keras\n",
    "'''\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from sklearn.datasets import load_files\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm # Used for the progress bar visualization\n",
    "import random\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Declare the data generation object for data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255, # rescale the image before feeding it to the cnn\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.5,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGenerate augmented images for waldo (do it only once)\\n'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Generate augmented images for waldo (do it only once)\n",
    "'''\n",
    "\n",
    "# waldo_filenames = np.array(glob(\"waldo_dataset/original_waldo/*\"))\n",
    "# for filename in waldo_filenames:\n",
    "#     img = load_img(filename)\n",
    "#     x = img_to_array(img)\n",
    "#     x = x.reshape((1,) + x.shape)\n",
    "#     i = 0\n",
    "#     for batch in datagen.flow(x, batch_size=1,\n",
    "#                               save_to_dir='waldo_dataset/train_32/waldo', \n",
    "#                               save_prefix='new_waldo', \n",
    "#                               save_format='jpg'):\n",
    "#         i += 1\n",
    "#         if i > 20:\n",
    "#             break  # the flow may yield batches indefinitely\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waldo dataset contains 604 images\n",
      "Notwaldo dataset contains 5337 images\n"
     ]
    }
   ],
   "source": [
    "# The following function loads a data set along with the targets \n",
    "# Note that the directory has to have at least two folders containing different classes\n",
    "# The following function was taken from dog breed classification project\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    files = np.array(data['filenames'])\n",
    "    targets = np.array(data['target'])\n",
    "    return files, targets\n",
    "\n",
    "# Declare the training (all_files) and test datasets along with their labels\n",
    "all_files, all_targets = load_dataset('waldo_dataset/train_32')\n",
    "test_files, test_targets = load_dataset('waldo_dataset/test')\n",
    "\n",
    "\n",
    "# Shuffle the data to avoid a bias\n",
    "rand = np.random.RandomState(10)\n",
    "shuffle = rand.permutation(len(all_files))\n",
    "all_files, all_targets = all_files[shuffle], all_targets[shuffle]\n",
    "\n",
    "\n",
    "# Show statistics about the data\n",
    "waldoFiles = np.array(glob(\"waldo_dataset/train_32/waldo/*\"))\n",
    "notWaldoFiles = np.array(glob(\"waldo_dataset/train_32/notwaldo/*\"))\n",
    "print('Waldo dataset contains ' + str(len(waldoFiles)) + ' images')\n",
    "print('Notwaldo dataset contains ' + str(len(notWaldoFiles)) + ' images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAGzCAYAAADUo+joAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x137a88400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use it tov visualize the data\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "objects = ('Waldo', 'Not Waldo')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [len(waldoFiles), len(notWaldoFiles)]\n",
    " \n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Number of entries in the dataset')\n",
    "plt.title('Waldo data exploration')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use this function to resize an image into 32x32 size\n",
    "def resize_img(filename, key):\n",
    "    image = cv2.imread(filename)\n",
    "    r = 100.0 / image.shape[1]\n",
    "    dim = (100, int(image.shape[0] *r))\n",
    "    imageresized = cv2.resize(image,(32,32),dim,interpolation = cv2.INTER_AREA)\n",
    "    cv2.imwrite('imageresized_{}.jpg'.format(key), imageresized)\n",
    "    \n",
    "# Use this code to resize all the images in the directory (use it only once)\n",
    "# waldoFilesnew = np.array(glob(\"waldo_dataset/test/waldo/*\"))\n",
    "# key = 0    \n",
    "# for image_file in waldoFilesnew:\n",
    "#     resize_img(image_file, key)\n",
    "#     key += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ekaterina/anaconda/lib/python3.6/site-packages/skimage/feature/_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "CREATE THE SVM CLASSIFIER\n",
    "'''\n",
    "from skimage.feature import hog\n",
    "import skimage as skimage\n",
    "\n",
    "# Calculate HOGs for all the images in the training set\n",
    "hog_descriptors = []\n",
    "for img in all_files:\n",
    "    timg = skimage.color.rgb2grey(cv2.imread(img))\n",
    "    hog_descriptors.append(hog(timg, orientations=9, pixels_per_cell=(8, 8), \n",
    "                                      cells_per_block=(3, 3), \n",
    "                                      visualise=False, \n",
    "                                      transform_sqrt=False, \n",
    "                                      feature_vector=True, \n",
    "                                      normalise=None))\n",
    "\n",
    "# Calculate HOGs for all the images in the testing set\n",
    "hog_descriptors_test = []\n",
    "for img in test_files:\n",
    "    timg = skimage.color.rgb2grey(cv2.imread(img))\n",
    "    hog_descriptors_test.append(skimage.feature.hog(timg, orientations=9, pixels_per_cell=(8, 8), \n",
    "                                      cells_per_block=(3, 3), \n",
    "                                      visualise=False, \n",
    "                                      transform_sqrt=False, \n",
    "                                      feature_vector=True, \n",
    "                                      normalise=None))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train SVM model\n",
    "from sklearn.svm import SVC\n",
    "from time import time\n",
    "t0=time()\n",
    "clf = SVC(probability=True)\n",
    "clf.fit(hog_descriptors, all_targets)\n",
    "t1=time()\n",
    "print('The model was trained in ' + str(t1 - t0) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TEST THE SVM CLASSIFIER\n",
    "'''\n",
    "count_correct = 0\n",
    "threshold = 0.5\n",
    "for i in range(len(hog_descriptors_test)):\n",
    "    # waldo probability\n",
    "    waldo_prob = np.squeeze(clf.predict_proba(hog_descriptors_test[i].reshape(1, -1)))[0]\n",
    "    if ((waldo_prob < threshold and test_targets[i] == 0) or (waldo_prob >= threshold and test_targets[i] == 1)):\n",
    "        count_correct += 1\n",
    "print('the accuracy score of the SVM classifier is ', count_correct / len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5941/5941 [00:01<00:00, 3401.78it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 3144.75it/s]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "CREATE THE CNN CLASSIFIER\n",
    "'''\n",
    "\n",
    "# Preprocess the images in order to use Keras with tensorflow backend\n",
    "# (I took this code from the dog breed classification project)\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(32, 32))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (64, 64, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 64, 64, 3) and return 4D tensor\n",
    "    result = np.expand_dims(x, axis=0)\n",
    "    return result\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "train_tensors = paths_to_tensor(all_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 16)        784       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 32)        8224      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 64)          32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 42,865\n",
      "Trainable params: 42,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Declare the convolutional neural network\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=4, strides=1, padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=4, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4752 samples, validate on 1189 samples\n",
      "Epoch 1/2\n",
      "4720/4752 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9943Epoch 00000: val_loss improved from inf to 0.06065, saving model to saved_models/best.hdf5\n",
      "4752/4752 [==============================] - 5s - loss: 0.0159 - acc: 0.9943 - val_loss: 0.0606 - val_acc: 0.9815\n",
      "Epoch 2/2\n",
      "4740/4752 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9958Epoch 00001: val_loss did not improve\n",
      "4752/4752 [==============================] - 5s - loss: 0.0109 - acc: 0.9958 - val_loss: 0.0638 - val_acc: 0.9823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13514a940>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use this to save the model with the best score for future retraining\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_tensors, all_targets, \n",
    "          validation_split=0.2,\n",
    "          epochs=2, \n",
    "          batch_size=20, \n",
    "          callbacks=[checkpointer], \n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Test the CNN Classifier\n",
    "'''\n",
    "def img_to_tensor(img):\n",
    "    result = np.expand_dims(img, axis=0)\n",
    "    return result\n",
    "\n",
    "def predict_waldo(img):\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    return np.squeeze(model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy score of the CNN classifier is  0.9\n"
     ]
    }
   ],
   "source": [
    "count_correct = 0\n",
    "threshold = 0.6\n",
    "for i in range(len(test_files)):\n",
    "    file_path = test_files[i]\n",
    "    file = load_img(file_path, target_size=(32, 32))\n",
    "    file = image.img_to_array(file).astype('float32')/255\n",
    "    score = predict_waldo(file)\n",
    "    if ((score < threshold and test_targets[i] == 0) or (score >= threshold and test_targets[i] == 1)):\n",
    "        count_correct += 1\n",
    "        \n",
    "print('the accuracy score of the CNN classifier is ', count_correct / len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "OBJECT DETECTION PART\n",
    "'''\n",
    "# Note: since CNN showed better results than SVM with HOG I'm going to use CNN for the object detection part\n",
    "\n",
    "# Create a sliding window\n",
    "def sliding_window(image, stepSize, windowSize):\n",
    "    # slide a window across the image\n",
    "    for y in range(0, image.shape[0], stepSize):\n",
    "        for x in range(0, image.shape[1], stepSize):\n",
    "            # yield the current window\n",
    "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])\n",
    "\n",
    "# Create the image pyramid for more accurate results\n",
    "def pyramid(image, scale, minSize=(30, 30)):\n",
    "    # yield the original image\n",
    "    yield(image)\n",
    " \n",
    "    # keep looping over the pyramid\n",
    "    while True:\n",
    "        # compute the new dimensions of the image and resize it\n",
    "        w = int(image.shape[1] / scale)\n",
    "        image = resize_im(image, width=w)\n",
    " \n",
    "        # if the resized image does not meet the supplied minimum\n",
    "        # size, then stop constructing the pyramid\n",
    "        if image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n",
    "            break\n",
    " \n",
    "        # yield the next image in the pyramid\n",
    "        yield(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Save image from a window for hard negative mining'''\n",
    "img = image.load_img('test.jpg', target_size=(32, 32))\n",
    "img = image.img_to_array(img).astype('float32')/255\n",
    "def save_img(img, key):    \n",
    "#     cv2.imwrite('waldo_dataset/hard_neg/hardmin_{}.jpg'.format(key), cv2.cvtColor(img.astype('float32')*255, cv2.COLOR_RGB2BGR))\n",
    "    cv2.imwrite('waldo_dataset/hard_neg13/notwaldo/hardmin13_{}.jpg'.format(key), img.astype('float32')*255)\n",
    "\n",
    "# save_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fp_rate(FP, total):\n",
    "    return FP / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original image name is waldo_dataset/original_images/14.jpg\n",
      "The efficiency of this is model is  0.5\n",
      "The efficiency of this is model is  0.3333333333333333\n",
      "The efficiency of this is model is  0.25\n",
      "The efficiency of this is model is  0.2\n",
      "The efficiency of this is model is  0.16666666666666666\n",
      "The efficiency of this is model is  0.14285714285714285\n",
      "The efficiency of this is model is  0.125\n",
      "The efficiency of this is model is  0.1111111111111111\n",
      "The efficiency of this is model is  0.1\n",
      "The efficiency of this is model is  0.09090909090909091\n",
      "The efficiency of this is model is  0.08333333333333333\n",
      "The efficiency of this is model is  0.07692307692307693\n",
      "The efficiency of this is model is  0.07142857142857142\n",
      "The efficiency of this is model is  0.06666666666666667\n",
      "The efficiency of this is model is  0.0625\n",
      "The efficiency of this is model is  0.058823529411764705\n",
      "The efficiency of this is model is  0.05555555555555555\n",
      "The efficiency of this is model is  0.05263157894736842\n",
      "The efficiency of this is model is  0.05\n",
      "The efficiency of this is model is  0.047619047619047616\n",
      "The efficiency of this is model is  0.045454545454545456\n",
      "The efficiency of this is model is  0.043478260869565216\n",
      "The efficiency of this is model is  0.041666666666666664\n",
      "The efficiency of this is model is  0.04\n",
      "The efficiency of this is model is  0.038461538461538464\n",
      "The efficiency of this is model is  0.037037037037037035\n",
      "The efficiency of this is model is  0.03571428571428571\n",
      "The efficiency of this is model is  0.034482758620689655\n",
      "The efficiency of this is model is  0.03333333333333333\n",
      "The efficiency of this is model is  0.03225806451612903\n",
      "The efficiency of this is model is  0.03125\n",
      "The efficiency of this is model is  0.030303030303030304\n",
      "The efficiency of this is model is  0.029411764705882353\n",
      "The efficiency of this is model is  0.02857142857142857\n",
      "The efficiency of this is model is  0.027777777777777776\n",
      "The efficiency of this is model is  0.02702702702702703\n",
      "The efficiency of this is model is  0.02631578947368421\n",
      "The efficiency of this is model is  0.02564102564102564\n",
      "The efficiency of this is model is  0.025\n",
      "The efficiency of this is model is  0.024390243902439025\n",
      "The efficiency of this is model is  0.023809523809523808\n",
      "The efficiency of this is model is  0.023255813953488372\n",
      "The efficiency of this is model is  0.022727272727272728\n",
      "The efficiency of this is model is  0.022222222222222223\n",
      "The efficiency of this is model is  0.021739130434782608\n",
      "The efficiency of this is model is  0.02127659574468085\n",
      "The efficiency of this is model is  0.020833333333333332\n",
      "The efficiency of this is model is  0.02040816326530612\n",
      "The efficiency of this is model is  0.02\n",
      "The efficiency of this is model is  0.0196078431372549\n",
      "The efficiency of this is model is  0.019230769230769232\n",
      "The efficiency of this is model is  0.018867924528301886\n",
      "The efficiency of this is model is  0.018518518518518517\n",
      "The efficiency of this is model is  0.01818181818181818\n",
      "The efficiency of this is model is  0.017857142857142856\n",
      "The efficiency of this is model is  0.017543859649122806\n",
      "The efficiency of this is model is  0.017241379310344827\n",
      "The efficiency of this is model is  0.01694915254237288\n",
      "The efficiency of this is model is  0.016666666666666666\n",
      "The efficiency of this is model is  0.01639344262295082\n",
      "The efficiency of this is model is  0.016129032258064516\n",
      "The efficiency of this is model is  0.015873015873015872\n",
      "The efficiency of this is model is  0.015625\n",
      "The efficiency of this is model is  0.015384615384615385\n",
      "The efficiency of this is model is  0.015151515151515152\n",
      "The efficiency of this is model is  0.014925373134328358\n",
      "The efficiency of this is model is  0.014705882352941176\n",
      "The efficiency of this is model is  0.014492753623188406\n",
      "The efficiency of this is model is  0.014285714285714285\n",
      "The efficiency of this is model is  0.014084507042253521\n",
      "The efficiency of this is model is  0.013888888888888888\n",
      "The efficiency of this is model is  0.0136986301369863\n",
      "The efficiency of this is model is  0.013513513513513514\n",
      "The efficiency of this is model is  0.013333333333333334\n",
      "The efficiency of this is model is  0.013157894736842105\n",
      "The efficiency of this is model is  0.012987012987012988\n",
      "The efficiency of this is model is  0.01282051282051282\n",
      "The efficiency of this is model is  0.012658227848101266\n",
      "The efficiency of this is model is  0.0125\n",
      "The efficiency of this is model is  0.012345679012345678\n",
      "The efficiency of this is model is  0.012195121951219513\n",
      "The efficiency of this is model is  0.012048192771084338\n",
      "The efficiency of this is model is  0.011904761904761904\n",
      "The efficiency of this is model is  0.011764705882352941\n",
      "The efficiency of this is model is  0.011627906976744186\n",
      "The efficiency of this is model is  0.011494252873563218\n",
      "The efficiency of this is model is  0.011363636363636364\n",
      "The efficiency of this is model is  0.011235955056179775\n",
      "The efficiency of this is model is  0.011111111111111112\n",
      "The efficiency of this is model is  0.01098901098901099\n",
      "The efficiency of this is model is  0.010869565217391304\n",
      "The efficiency of this is model is  0.010752688172043012\n",
      "The efficiency of this is model is  0.010638297872340425\n",
      "The efficiency of this is model is  0.010526315789473684\n",
      "The efficiency of this is model is  0.010416666666666666\n",
      "The efficiency of this is model is  0.010309278350515464\n",
      "The efficiency of this is model is  0.01020408163265306\n",
      "The efficiency of this is model is  0.010101010101010102\n",
      "The efficiency of this is model is  0.01\n",
      "The efficiency of this is model is  0.009900990099009901\n",
      "The efficiency of this is model is  0.00980392156862745\n",
      "The efficiency of this is model is  0.009708737864077669\n",
      "The efficiency of this is model is  0.009615384615384616\n",
      "The efficiency of this is model is  0.009523809523809525\n",
      "The efficiency of this is model is  0.009433962264150943\n",
      "The efficiency of this is model is  0.009345794392523364\n",
      "The efficiency of this is model is  0.009259259259259259\n",
      "The efficiency of this is model is  0.009174311926605505\n",
      "The efficiency of this is model is  0.00909090909090909\n",
      "The efficiency of this is model is  0.009009009009009009\n",
      "The efficiency of this is model is  0.008928571428571428\n",
      "The efficiency of this is model is  0.008849557522123894\n",
      "The efficiency of this is model is  0.008771929824561403\n",
      "The efficiency of this is model is  0.008695652173913044\n",
      "The efficiency of this is model is  0.008620689655172414\n",
      "The efficiency of this is model is  0.008547008547008548\n",
      "The efficiency of this is model is  0.00847457627118644\n",
      "The efficiency of this is model is  0.008403361344537815\n",
      "The efficiency of this is model is  0.008333333333333333\n",
      "The efficiency of this is model is  0.008264462809917356\n",
      "The efficiency of this is model is  0.00819672131147541\n",
      "The efficiency of this is model is  0.008130081300813009\n",
      "The efficiency of this is model is  0.008064516129032258\n",
      "The efficiency of this is model is  0.008\n",
      "The efficiency of this is model is  0.007936507936507936\n",
      "The efficiency of this is model is  0.007874015748031496\n",
      "The efficiency of this is model is  0.0078125\n",
      "The efficiency of this is model is  0.007751937984496124\n",
      "The efficiency of this is model is  0.007692307692307693\n",
      "The efficiency of this is model is  0.007633587786259542\n",
      "The efficiency of this is model is  0.007575757575757576\n",
      "The efficiency of this is model is  0.007518796992481203\n",
      "The efficiency of this is model is  0.007462686567164179\n",
      "The efficiency of this is model is  0.007407407407407408\n",
      "The efficiency of this is model is  0.007352941176470588\n",
      "The efficiency of this is model is  0.0072992700729927005\n",
      "The efficiency of this is model is  0.007246376811594203\n",
      "The efficiency of this is model is  0.007194244604316547\n",
      "The efficiency of this is model is  0.007142857142857143\n",
      "The efficiency of this is model is  0.0070921985815602835\n",
      "The efficiency of this is model is  0.007042253521126761\n",
      "The efficiency of this is model is  0.006993006993006993\n",
      "The efficiency of this is model is  0.006944444444444444\n",
      "The efficiency of this is model is  0.006896551724137931\n",
      "The efficiency of this is model is  0.00684931506849315\n",
      "The efficiency of this is model is  0.006802721088435374\n",
      "The efficiency of this is model is  0.006756756756756757\n",
      "The efficiency of this is model is  0.006711409395973154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The efficiency of this is model is  0.006666666666666667\n",
      "The efficiency of this is model is  0.006622516556291391\n",
      "The efficiency of this is model is  0.006578947368421052\n",
      "The efficiency of this is model is  0.006535947712418301\n",
      "The efficiency of this is model is  0.006493506493506494\n",
      "The efficiency of this is model is  0.0064516129032258064\n",
      "The efficiency of this is model is  0.00641025641025641\n",
      "The efficiency of this is model is  0.006369426751592357\n",
      "The efficiency of this is model is  0.006329113924050633\n",
      "The efficiency of this is model is  0.006289308176100629\n",
      "The efficiency of this is model is  0.00625\n",
      "The efficiency of this is model is  0.006211180124223602\n",
      "The efficiency of this is model is  0.006172839506172839\n",
      "The efficiency of this is model is  0.006134969325153374\n",
      "The efficiency of this is model is  0.006097560975609756\n",
      "The efficiency of this is model is  0.006060606060606061\n",
      "The efficiency of this is model is  0.006024096385542169\n",
      "The efficiency of this is model is  0.011976047904191617\n",
      "The efficiency of this is model is  0.017857142857142856\n",
      "The efficiency of this is model is  0.023668639053254437\n",
      "The efficiency of this is model is  0.023529411764705882\n",
      "The efficiency of this is model is  0.023391812865497075\n",
      "The efficiency of this is model is  0.023255813953488372\n",
      "The efficiency of this is model is  0.023121387283236993\n",
      "The efficiency of this is model is  0.022988505747126436\n",
      "The efficiency of this is model is  0.022857142857142857\n",
      "The efficiency of this is model is  0.022727272727272728\n",
      "The efficiency of this is model is  0.022598870056497175\n",
      "The efficiency of this is model is  0.02247191011235955\n",
      "The efficiency of this is model is  0.0223463687150838\n",
      "The efficiency of this is model is  0.022222222222222223\n",
      "The efficiency of this is model is  0.022099447513812154\n",
      "The efficiency of this is model is  0.02197802197802198\n",
      "The efficiency of this is model is  0.02185792349726776\n",
      "The efficiency of this is model is  0.021739130434782608\n",
      "The efficiency of this is model is  0.021621621621621623\n",
      "The efficiency of this is model is  0.021505376344086023\n",
      "The efficiency of this is model is  0.0213903743315508\n",
      "The efficiency of this is model is  0.02127659574468085\n",
      "The efficiency of this is model is  0.021164021164021163\n",
      "The efficiency of this is model is  0.021052631578947368\n",
      "The efficiency of this is model is  0.020942408376963352\n",
      "The efficiency of this is model is  0.020833333333333332\n",
      "The efficiency of this is model is  0.02072538860103627\n",
      "The efficiency of this is model is  0.020618556701030927\n",
      "The efficiency of this is model is  0.020512820512820513\n",
      "The efficiency of this is model is  0.02040816326530612\n",
      "The efficiency of this is model is  0.02030456852791878\n",
      "The efficiency of this is model is  0.020202020202020204\n",
      "The efficiency of this is model is  0.020100502512562814\n",
      "The efficiency of this is model is  0.02\n",
      "The efficiency of this is model is  0.01990049751243781\n",
      "The efficiency of this is model is  0.019801980198019802\n",
      "The efficiency of this is model is  0.019704433497536946\n",
      "The efficiency of this is model is  0.0196078431372549\n",
      "The efficiency of this is model is  0.01951219512195122\n",
      "The efficiency of this is model is  0.019417475728155338\n",
      "The efficiency of this is model is  0.01932367149758454\n",
      "The efficiency of this is model is  0.019230769230769232\n",
      "The efficiency of this is model is  0.019138755980861243\n",
      "The efficiency of this is model is  0.01904761904761905\n",
      "The efficiency of this is model is  0.018957345971563982\n",
      "The efficiency of this is model is  0.018867924528301886\n",
      "The efficiency of this is model is  0.018779342723004695\n",
      "The efficiency of this is model is  0.018691588785046728\n",
      "The efficiency of this is model is  0.018604651162790697\n",
      "The efficiency of this is model is  0.018518518518518517\n",
      "The efficiency of this is model is  0.018433179723502304\n",
      "The efficiency of this is model is  0.01834862385321101\n",
      "The efficiency of this is model is  0.0182648401826484\n",
      "The efficiency of this is model is  0.01818181818181818\n",
      "The efficiency of this is model is  0.01809954751131222\n",
      "The efficiency of this is model is  0.018018018018018018\n",
      "The efficiency of this is model is  0.017937219730941704\n",
      "The efficiency of this is model is  0.017857142857142856\n",
      "The efficiency of this is model is  0.017777777777777778\n",
      "The efficiency of this is model is  0.017699115044247787\n",
      "The efficiency of this is model is  0.01762114537444934\n",
      "The efficiency of this is model is  0.017543859649122806\n",
      "The efficiency of this is model is  0.017467248908296942\n",
      "The efficiency of this is model is  0.017391304347826087\n",
      "The efficiency of this is model is  0.017316017316017316\n",
      "The efficiency of this is model is  0.017241379310344827\n",
      "The efficiency of this is model is  0.017167381974248927\n",
      "The efficiency of this is model is  0.017094017094017096\n",
      "The efficiency of this is model is  0.01702127659574468\n",
      "The efficiency of this is model is  0.01694915254237288\n",
      "The efficiency of this is model is  0.016877637130801686\n",
      "The efficiency of this is model is  0.01680672268907563\n",
      "The efficiency of this is model is  0.02092050209205021\n",
      "The efficiency of this is model is  0.025\n",
      "The efficiency of this is model is  0.029045643153526972\n",
      "The efficiency of this is model is  0.03305785123966942\n",
      "The efficiency of this is model is  0.037037037037037035\n",
      "The efficiency of this is model is  0.040983606557377046\n",
      "The efficiency of this is model is  0.044897959183673466\n",
      "The efficiency of this is model is  0.04878048780487805\n",
      "The efficiency of this is model is  0.05263157894736842\n",
      "The efficiency of this is model is  0.05241935483870968\n",
      "The efficiency of this is model is  0.05220883534136546\n",
      "The efficiency of this is model is  0.052\n",
      "The efficiency of this is model is  0.05179282868525897\n",
      "The efficiency of this is model is  0.051587301587301584\n",
      "The efficiency of this is model is  0.05138339920948617\n",
      "The efficiency of this is model is  0.051181102362204724\n",
      "The efficiency of this is model is  0.050980392156862744\n",
      "The efficiency of this is model is  0.05078125\n",
      "The efficiency of this is model is  0.05058365758754864\n",
      "The efficiency of this is model is  0.050387596899224806\n",
      "The efficiency of this is model is  0.05019305019305019\n",
      "The efficiency of this is model is  0.05\n",
      "The efficiency of this is model is  0.04980842911877394\n",
      "The efficiency of this is model is  0.05343511450381679\n",
      "The efficiency of this is model is  0.057034220532319393\n",
      "The efficiency of this is model is  0.06060606060606061\n",
      "The efficiency of this is model is  0.06037735849056604\n",
      "The efficiency of this is model is  0.06015037593984962\n",
      "The efficiency of this is model is  0.0599250936329588\n",
      "The efficiency of this is model is  0.05970149253731343\n",
      "The efficiency of this is model is  0.05947955390334572\n",
      "The efficiency of this is model is  0.05925925925925926\n",
      "The efficiency of this is model is  0.05904059040590406\n",
      "The efficiency of this is model is  0.0625\n",
      "The efficiency of this is model is  0.06593406593406594\n",
      "The efficiency of this is model is  0.06569343065693431\n",
      "The efficiency of this is model is  0.06545454545454546\n",
      "The efficiency of this is model is  0.06521739130434782\n",
      "The efficiency of this is model is  0.06498194945848375\n",
      "The efficiency of this is model is  0.06474820143884892\n",
      "The efficiency of this is model is  0.06451612903225806\n",
      "The efficiency of this is model is  0.06428571428571428\n",
      "The efficiency of this is model is  0.06405693950177936\n",
      "The efficiency of this is model is  0.06382978723404255\n",
      "The efficiency of this is model is  0.0636042402826855\n",
      "The efficiency of this is model is  0.06338028169014084\n",
      "The efficiency of this is model is  0.06315789473684211\n",
      "The efficiency of this is model is  0.06293706293706294\n",
      "The efficiency of this is model is  0.0627177700348432\n",
      "The efficiency of this is model is  0.0625\n",
      "The efficiency of this is model is  0.06228373702422145\n",
      "The efficiency of this is model is  0.06206896551724138\n",
      "The efficiency of this is model is  0.061855670103092786\n",
      "The efficiency of this is model is  0.06164383561643835\n",
      "The efficiency of this is model is  0.06143344709897611\n",
      "The efficiency of this is model is  0.061224489795918366\n",
      "The efficiency of this is model is  0.061016949152542375\n",
      "The efficiency of this is model is  0.060810810810810814\n",
      "The efficiency of this is model is  0.06060606060606061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The efficiency of this is model is  0.06040268456375839\n",
      "The efficiency of this is model is  0.06020066889632107\n",
      "The efficiency of this is model is  0.06\n",
      "The efficiency of this is model is  0.059800664451827246\n",
      "The efficiency of this is model is  0.059602649006622516\n",
      "The efficiency of this is model is  0.0594059405940594\n",
      "The efficiency of this is model is  0.05921052631578947\n",
      "The efficiency of this is model is  0.05901639344262295\n",
      "The efficiency of this is model is  0.058823529411764705\n",
      "The efficiency of this is model is  0.05863192182410423\n",
      "The efficiency of this is model is  0.05844155844155844\n",
      "The efficiency of this is model is  0.05825242718446602\n",
      "The efficiency of this is model is  0.05806451612903226\n",
      "The efficiency of this is model is  0.05787781350482315\n",
      "The efficiency of this is model is  0.057692307692307696\n",
      "The efficiency of this is model is  0.05750798722044728\n",
      "The efficiency of this is model is  0.05732484076433121\n",
      "The efficiency of this is model is  0.05714285714285714\n",
      "The efficiency of this is model is  0.056962025316455694\n",
      "The efficiency of this is model is  0.056782334384858045\n",
      "The efficiency of this is model is  0.05660377358490566\n",
      "The efficiency of this is model is  0.05642633228840126\n",
      "The efficiency of this is model is  0.05625\n",
      "The efficiency of this is model is  0.056074766355140186\n",
      "The efficiency of this is model is  0.055900621118012424\n",
      "The efficiency of this is model is  0.05572755417956656\n",
      "The efficiency of this is model is  0.05555555555555555\n",
      "The efficiency of this is model is  0.055384615384615386\n",
      "The efficiency of this is model is  0.05521472392638037\n",
      "The efficiency of this is model is  0.05504587155963303\n",
      "The efficiency of this is model is  0.054878048780487805\n",
      "The efficiency of this is model is  0.0547112462006079\n",
      "The efficiency of this is model is  0.05454545454545454\n",
      "The efficiency of this is model is  0.054380664652567974\n",
      "The efficiency of this is model is  0.0572289156626506\n",
      "The efficiency of this is model is  0.06006006006006006\n",
      "The efficiency of this is model is  0.059880239520958084\n",
      "The efficiency of this is model is  0.0626865671641791\n",
      "The efficiency of this is model is  0.06547619047619048\n",
      "The efficiency of this is model is  0.06528189910979229\n",
      "The efficiency of this is model is  0.0650887573964497\n",
      "The efficiency of this is model is  0.06489675516224189\n",
      "The efficiency of this is model is  0.06470588235294118\n",
      "The efficiency of this is model is  0.06744868035190615\n",
      "The efficiency of this is model is  0.07017543859649122\n",
      "The efficiency of this is model is  0.0728862973760933\n",
      "The efficiency of this is model is  0.0755813953488372\n",
      "The efficiency of this is model is  0.0782608695652174\n",
      "The efficiency of this is model is  0.08092485549132948\n",
      "The efficiency of this is model is  0.08357348703170028\n",
      "The efficiency of this is model is  0.08620689655172414\n",
      "The efficiency of this is model is  0.08882521489971347\n",
      "The efficiency of this is model is  0.09142857142857143\n",
      "The efficiency of this is model is  0.09401709401709402\n",
      "The efficiency of this is model is  0.09659090909090909\n",
      "The efficiency of this is model is  0.09631728045325778\n",
      "The efficiency of this is model is  0.096045197740113\n",
      "The efficiency of this is model is  0.09577464788732394\n",
      "The efficiency of this is model is  0.09550561797752809\n",
      "The efficiency of this is model is  0.09803921568627451\n",
      "The efficiency of this is model is  0.1005586592178771\n",
      "The efficiency of this is model is  0.10306406685236769\n",
      "The efficiency of this is model is  0.10277777777777777\n",
      "The efficiency of this is model is  0.10249307479224377\n",
      "The efficiency of this is model is  0.10497237569060773\n",
      "The efficiency of this is model is  0.10743801652892562\n",
      "The efficiency of this is model is  0.10989010989010989\n",
      "The efficiency of this is model is  0.1095890410958904\n",
      "The efficiency of this is model is  0.1092896174863388\n",
      "The efficiency of this is model is  0.11171662125340599\n",
      "The efficiency of this is model is  0.11413043478260869\n",
      "The efficiency of this is model is  0.11653116531165311\n",
      "The efficiency of this is model is  0.11891891891891893\n",
      "The efficiency of this is model is  0.11859838274932614\n",
      "The efficiency of this is model is  0.11827956989247312\n",
      "The efficiency of this is model is  0.11796246648793565\n",
      "The efficiency of this is model is  0.11764705882352941\n",
      "The efficiency of this is model is  0.11733333333333333\n",
      "The efficiency of this is model is  0.11702127659574468\n",
      "The efficiency of this is model is  0.11671087533156499\n",
      "The efficiency of this is model is  0.11904761904761904\n",
      "The efficiency of this is model is  0.12137203166226913\n",
      "The efficiency of this is model is  0.12105263157894737\n",
      "The efficiency of this is model is  0.12073490813648294\n",
      "The efficiency of this is model is  0.12041884816753927\n",
      "The efficiency of this is model is  0.12010443864229765\n",
      "The efficiency of this is model is  0.11979166666666667\n",
      "The efficiency of this is model is  0.11948051948051948\n",
      "The efficiency of this is model is  0.11917098445595854\n",
      "The efficiency of this is model is  0.11886304909560723\n",
      "The efficiency of this is model is  0.11855670103092783\n",
      "The efficiency of this is model is  0.11825192802056556\n",
      "The efficiency of this is model is  0.11794871794871795\n",
      "The efficiency of this is model is  0.11764705882352941\n",
      "The efficiency of this is model is  0.11734693877551021\n",
      "The efficiency of this is model is  0.11704834605597965\n",
      "The efficiency of this is model is  0.116751269035533\n",
      "The efficiency of this is model is  0.11645569620253164\n",
      "The efficiency of this is model is  0.11616161616161616\n",
      "The efficiency of this is model is  0.11586901763224182\n",
      "The efficiency of this is model is  0.11557788944723618\n",
      "The efficiency of this is model is  0.11528822055137844\n",
      "The efficiency of this is model is  0.115\n",
      "The efficiency of this is model is  0.11471321695760599\n",
      "The efficiency of this is model is  0.11442786069651742\n",
      "The efficiency of this is model is  0.1141439205955335\n",
      "The efficiency of this is model is  0.11386138613861387\n",
      "The efficiency of this is model is  0.11358024691358025\n",
      "The efficiency of this is model is  0.11330049261083744\n",
      "The efficiency of this is model is  0.11302211302211303\n",
      "The efficiency of this is model is  0.11274509803921569\n",
      "The efficiency of this is model is  0.11246943765281174\n",
      "The efficiency of this is model is  0.11219512195121951\n",
      "The efficiency of this is model is  0.11192214111922141\n",
      "The efficiency of this is model is  0.11165048543689321\n",
      "The efficiency of this is model is  0.11138014527845036\n",
      "The efficiency of this is model is  0.1111111111111111\n",
      "The efficiency of this is model is  0.1108433734939759\n",
      "The efficiency of this is model is  0.11057692307692307\n",
      "The efficiency of this is model is  0.11031175059952038\n",
      "The efficiency of this is model is  0.11004784688995216\n",
      "The efficiency of this is model is  0.10978520286396182\n",
      "The efficiency of this is model is  0.10952380952380952\n",
      "The efficiency of this is model is  0.10926365795724466\n",
      "The efficiency of this is model is  0.10900473933649289\n",
      "The efficiency of this is model is  0.10874704491725769\n",
      "The efficiency of this is model is  0.10849056603773585\n",
      "The efficiency of this is model is  0.10823529411764705\n",
      "The efficiency of this is model is  0.107981220657277\n",
      "The efficiency of this is model is  0.10772833723653395\n",
      "The efficiency of this is model is  0.10747663551401869\n",
      "The efficiency of this is model is  0.10722610722610723\n",
      "The efficiency of this is model is  0.10697674418604651\n",
      "The efficiency of this is model is  0.10672853828306264\n",
      "The efficiency of this is model is  0.10648148148148148\n",
      "The efficiency of this is model is  0.10623556581986143\n",
      "The efficiency of this is model is  0.10599078341013825\n",
      "The efficiency of this is model is  0.10574712643678161\n",
      "The efficiency of this is model is  0.10550458715596331\n",
      "The efficiency of this is model is  0.10755148741418764\n",
      "The efficiency of this is model is  0.1095890410958904\n",
      "The efficiency of this is model is  0.11161731207289294\n",
      "The efficiency of this is model is  0.11363636363636363\n",
      "The efficiency of this is model is  0.11564625850340136\n",
      "The efficiency of this is model is  0.11764705882352941\n",
      "The efficiency of this is model is  0.11963882618510158\n",
      "The efficiency of this is model is  0.11936936936936937\n",
      "The efficiency of this is model is  0.11910112359550562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The efficiency of this is model is  0.11883408071748879\n",
      "The efficiency of this is model is  0.1185682326621924\n",
      "The efficiency of this is model is  0.11830357142857142\n",
      "The efficiency of this is model is  0.11804008908685969\n",
      "The efficiency of this is model is  0.11777777777777777\n",
      "The efficiency of this is model is  0.11751662971175167\n",
      "The efficiency of this is model is  0.1172566371681416\n",
      "The efficiency of this is model is  0.11699779249448124\n",
      "The efficiency of this is model is  0.11674008810572688\n",
      "The efficiency of this is model is  0.11648351648351649\n",
      "The efficiency of this is model is  0.1162280701754386\n",
      "The efficiency of this is model is  0.11597374179431072\n",
      "The efficiency of this is model is  "
     ]
    }
   ],
   "source": [
    "'''\n",
    "TEST THE OBJECT DETECTION PART\n",
    "'''\n",
    "originalFiles = np.array(glob(\"waldo_dataset/original_images/*\"))\n",
    "threshold = 0.7\n",
    "\n",
    "from time import sleep\n",
    "img_path = originalFiles[5]\n",
    "print('The original image name is', img_path)\n",
    "image = cv2.imread(img_path)\n",
    "winW = 32\n",
    "winH = 32\n",
    "y_pred = []\n",
    "key = 0 # use it for saving images during hard negative mining\n",
    "percentage_chance = 0.3 # Probability at which images are going to be saved during hard negative mining\n",
    "\n",
    "''' CHOOSE THE MODEL HERE '''\n",
    "model = load_model('saved_models/best_nod.hdf5')\n",
    "\n",
    "# Use these variables for model evaluation\n",
    "FP = 1\n",
    "total = 1\n",
    "for resized in pyramid(image, scale=0.5):\n",
    "    for (x, y, window) in sliding_window(resized, stepSize=16, windowSize=(winW, winH)):\n",
    "            # if the window does not meet our desired window size, ignore it\n",
    "            window = window.astype('float32')/255\n",
    "            if window.shape[0] != winH or window.shape[1] != winW:\n",
    "                continue\n",
    "            if predict_waldo(window) > threshold:\n",
    "                  # uncomment it for saving images during hard negative mining\n",
    "#                 if random.random() < percentage_chance:\n",
    "#                     save_img(window, key)\n",
    "                cv2.rectangle(image, (x, y), (x + winW, y + winH), (255, 0, 0), 2)\n",
    "                key += 1\n",
    "                FP += 1\n",
    "            total += 1\n",
    "            print('The efficiency of this is model is ', fp_rate(FP, total))\n",
    "                \n",
    "            # since we do not have a classifier, we'll just draw the window\n",
    "            clone = resized.copy()\n",
    "            cv2.rectangle(clone, (x, y), (x + winW, y + winH), (0, 255, 0), 2)\n",
    "            cv2.imshow(\"Window\", clone)\n",
    "            cv2.waitKey(33)\n",
    "            sleep(0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/120 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 120/120 [00:00<00:00, 3548.83it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96 samples, validate on 24 samples\n",
      "Epoch 1/4\n",
      "80/96 [========================>.....] - ETA: 0s - loss: 0.3156 - acc: 0.9000Epoch 00000: val_loss improved from inf to 0.04531, saving model to saved_models/hard_neg9.hdf5\n",
      "96/96 [==============================] - 0s - loss: 0.2706 - acc: 0.9167 - val_loss: 0.0453 - val_acc: 0.9583\n",
      "Epoch 2/4\n",
      "60/96 [=================>............] - ETA: 0s - loss: 0.0183 - acc: 0.9833Epoch 00001: val_loss improved from 0.04531 to 0.02253, saving model to saved_models/hard_neg9.hdf5\n",
      "96/96 [==============================] - 0s - loss: 0.0196 - acc: 0.9896 - val_loss: 0.0225 - val_acc: 1.0000\n",
      "Epoch 3/4\n",
      "80/96 [========================>.....] - ETA: 0s - loss: 0.0430 - acc: 0.9875    Epoch 00002: val_loss did not improve\n",
      "96/96 [==============================] - 0s - loss: 0.0367 - acc: 0.9896 - val_loss: 0.0686 - val_acc: 0.9583\n",
      "Epoch 4/4\n",
      "80/96 [========================>.....] - ETA: 0s - loss: 0.0118 - acc: 1.0000Epoch 00003: val_loss improved from 0.02253 to 0.01835, saving model to saved_models/hard_neg9.hdf5\n",
      "96/96 [==============================] - 0s - loss: 0.0099 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x135eedf98>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Implement Hard Negative Mining\n",
    "'''\n",
    "# Upload the images generated during hard negative miining\n",
    "hard_neg9_files, hard_neg9_targets = load_dataset('waldo_dataset/hard_neg9')\n",
    "hard_neg9_train_tensors = paths_to_tensor(hard_neg9_files).astype('float32')/255\n",
    "\n",
    "# Load the pretrained model\n",
    "model = load_model('saved_models/best.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/hard_neg9.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "# Retrain the model\n",
    "model.fit(hard_neg9_train_tensors, hard_neg9_targets, \n",
    "          validation_split=0.2,\n",
    "          epochs=4, \n",
    "          batch_size=20, \n",
    "          callbacks=[checkpointer], \n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
